{"name":"Persepolis","tagline":"is an java repo that will figure out the Bayesian Network By the parameters","body":"## Outline\r\nIn this project, a BN and a DBN is learned from the given data using Greedy Hill Climbing and random restarts. A directed graph without any edge is seen as the initial graph, then an algorithm called GHC is used and with this method, a better structure is found step by step supported by the scoring function, until a situation that every neighbor of the current status have lower score then the current, then random restart is executed. In this way, the best structure will be get. After that, parameter of this structure can be calculate so that inference can be done to predict the value.\r\n\r\n## Basic Steps\r\n###BN StructureLearning\r\nAt the very beginning, structure learning is necessary to find out the best-scored structure in BN. \r\nWith the initial network which has N vertex generated by the data class, in every step in GHC, program will find out the better scored structure in its neighbor, that structure will be seem as current structure. In this way, the current structure will be better and better until the program find a structure that all its neighbor have lower score, that means, a local best is found. To deal with this situation, random restart will be executed, a random graph generator will be called and a new random graph will be returned as the current structure, then GHC is applied again. After several times of random restart, a global best is found.\r\nIn the progress above, a TABU list is also applied when checking the neighbor of the current structure, if the neighbor is in the TABU list, ignore it and check the next one, else, calculate its score and add it into TABU list.\r\n\r\n###DBN StructureLearning\r\nAnalogously, structure learning in DBN also use GHC algorithm, random restart and TABU lists. The difference is that structure learning in GHC has 2N vertex(Which is double number of BN), but has no edge from time t to time t or for time t+1 to time t. When learning DBN structures, if a vertex has 3 parent vertex, which is the max number of a vertex, there will not any additional edge points to it.\r\n\r\n###ParameterLearning\r\n\r\nIn this step, probabilities should be determined given the optimal structure with certain standard.In the constructor, the test data is given for the program to learn the best structure,\r\nparameterLearning(dyllscore d1,data data1);\r\nKnowing all the parameters , is given by the following expression:\r\n<center><a href=\"http://imgur.com/aWnMixA\"><img src=\"http://i.imgur.com/aWnMixA.png\" title=\"source: imgur.com\" /></a></center>\r\nNote that: N’ are pseudo-counts, which equals 0.5 in this project.\r\nThe above formula can be described by the following program:\r\n```\r\nfor(int i=0; i<2*p_numberOfNode; i++){\r\n\tfor(int j=0; j<p_dyqll[i]; j++){\r\n\t\tfor( int k=0; k<p_dyrll[i]; k++){\r\n\t\t\ttheta[i][j][k]=(d1.getCount(i, j, k)+constN)/(d1.getCounts(i, j)+p_dyrll[i]*constN);\r\n\t\t}\r\n\t}\r\n}\r\n```\r\n###Inference\r\nAfter leaned the parameters, the DB Network can be used to infer the most probably future data. As known in the section above, θijk, which is the probability that ith variable has kth value with jth parent config is calculated. This set of probability can be used for calculate the most possible values appear in the future.\r\nWhen predicting the ith variable, all other variable should also be specific so that a set of θijk can be get from the section above. The sum of the set of θijk is the probability of the appearance of the ith variable with the kth value. After compared all the probability that ith variable can take, the one with biggest probability should be the inference value of the ith variable.\r\n##Scoring functions\r\nScoring functions are necessary to calculate scores to the specific structures, a base class is provided to save all the possible algorithms to find the optimal solution to score the structure.In this project, two kinds of algorithms(log-likelihood and minimum description length) are ordered, each of the algorithms implements both the Bayesian network and the dynamic Bayesian network.\r\nThis is a abstract class, all the declarations are done in this class.\r\n\r\n###LLscore\r\nFirst, initialize the count[][][] and counts[][] given the train data and the DAG. Then determine the parent nodes of each nodes, \r\nList<String> ls= digraph1.getPais(data1.getVl().get(n));  \r\nTransfer the array of parent nodes in string to integer for convenience. Iterate the rll, determine the number of parents configurations\r\n```\r\narrayOfParents[aop]=parent;\r\nqll[n]*=rll[parent];\r\n```\r\nAfter that given the number of nodes, the number of parent configurations of each nodes, number of different values of each nodes, iterate the whole data file, \r\n```\r\nfor(int i=1;i<data1.getCore().size();i++)\r\nfor(int j=0;j<data1.getCore().get(i).size();j+=numberOfNode)\r\n```\r\neach set of values is corresponding to a certain count[][][],\r\n```\r\nfirstParameter=n;\r\nsecondParameter+=coef*weight;\r\nthirdParameter=Integer.parseInt(data1.getCore().get(i).get(n+j));\r\ncount[firstParameter][secondParameter][thirdParameter]++;\r\n```\r\nThen, it is easy to get the value of counts[][] given the count[][][],\r\n```\r\nfor(int i=0;i<numberOfNode;i++){\r\n\tfor(int j=0;j<qll[i];j++){\r\n\t\tfor(int k=0;k<rll[i];k++){\r\n\t\t\tcounts[i][j]+=count[i][j][k];\t\r\n\t\t}\r\n\t}\r\n}\r\n```\r\nFinally, apply log-likelihood algorithm with all the given parameters to get the final result in the Bayesian network.\r\n\r\n<center><a href=\"http://imgur.com/aWnMixA\"><img src=\"http://i.imgur.com/aWnMixA.png\" title=\"source: imgur.com\" /></a></center>\r\n\r\n\r\nNote that:  is count[i][j][k] and  is counts[i][j].\r\n\r\n###MDLscore\r\nMinimum description length is another scoring criterion in this project, all the initialization is done in the constructor.\r\n```\r\nmdlscore(data data1, Digraph<String> digraph1,double llscore, int[] qll)\r\n```\r\nthe score of the structure by using minimum description length algorithm can be achieved through the expression below:\r\n```\r\ndymdlscore = dyllscore - 0.5*Math.log(totalNumber)*B/Math.log(2);\r\n```\r\nNote that: is the total number of instances, and  denotes the network complexity, which is given by:\r\n```\r\nfor(int i=0;i<2*numberOfNode;i++){\r\n\tB=B+(dyrll[i]-1)*dyqll[i];\r\n}\r\n```\r\n###DyLLscore\r\nIn the terms of the log-likelihood score in the dynamic Bayesian network, the calculation is basically the same as it is in the Bayesian network. The difference only lies on the number of nodes, which needs to take careful consideration. Because it depends on two states, the number of nodes in each sets we should be two times of the actual number of nodes.\r\n```\r\ndyrll = new int[2*numberOfNode];\r\ndyqll=new int[2*numberOfNode];\r\n```\r\n###DyMDLscore\r\nIn the terms of the minimum description length score in the dynamic Bayesian network comparing to it in the Bayesian network, the only difference also lies on the number of nodes in each set.\r\n```\r\ndyrmim = new int[2*numberOfNode];\r\nfor(int i = 0 ; i<2*numberOfNode ; i++){\r\n\tdyrll[i]=rll[i%numberOfNode];\r\n\ttotalNumber=totalNumber + dyrll[i];\r\n}\r\n```\r\n##Efficiency\r\n###Array, ArrayList and LinkedList\r\nThe time complexity comparison is as follows:\r\n<center><a href=\"http://imgur.com/gEp0H46\"><img src=\"http://i.imgur.com/gEp0H46.png\" title=\"source: imgur.com\" /></a></center>\r\nadd() in the table refers to add(E e), and remove() refers to remove(int index)\r\nArrayList has O(n) time complexity for arbitrary indices of add/remove, but O(1) for the operation at the end of the list.\r\nLinkedList has O(n) time complexity for arbitrary indices of add/remove, but O(1) for operations at end/beginning of the List.\r\nThe difference of their performance is obvious. \r\n<a href=\"http://imgur.com/o9Pb51K\"><img src=\"http://i.imgur.com/o9Pb51K.png\" title=\"source: imgur.com\" /></a>\r\nLinkedList is faster in add and remove, but slower in get. Based on the complexity table and testing results, we can figure out when to use ArrayList or LinkedList. In brief, LinkedList should be preferred if:\r\nthere are no large number of random access of element\r\nthere are a large number of add/remove operations\r\nIn our project, the data class need only add data once(The data never changes), but is read several times, so ArrayList is a good choice for data. For other small data structures, LinkedList is seem in high efficiency, and sometimes for the small length-fixed structures, array is used.\r\n\r\n###Directed Graph(Adjacency matrix or adjacency list)\r\nAdjacency matrix or adjacency list? When facing this problem, it is important to make a decision for that to continue our project. It can not only have impact on the efficiency of the program but also can influence the stability. Multiple factor is considered in our project, as listed below.\r\n<center><a href=\"http://imgur.com/GirLr1J\"><img src=\"http://i.imgur.com/GirLr1J.png\" title=\"source: imgur.com\" /></a></center>\r\n\r\n\r\n\r\n\r\nAs can be seen in the chart above. An adjacency matrix occupy much more space in the memory, and adjacency list just save what it need. However, adjacency matrix have a higher speed to find a specific edge, but it is slower to iterate though the graph.\r\nIn our project, it is rare to have a graph with more than 20 vertex, so it will not occupy lots of memory. What’s more, we always need to look up parents of a specific vertex, which need to Iterate though the graph, so a data structure using adjacency list is generated.\r\n\r\n<center><a href=\"http://imgur.com/iDO0Lgj\"><img src=\"http://i.imgur.com/iDO0Lgj.png\" title=\"source: imgur.com\" /></a></center>\r\n\r\n\r\n\r\n###Data Structure in Parameter Learning\r\nAs we known, the score is typically based on the count[ ][ ][ ] and the counts[ ][ ] in this project. However, iterating the whole data is time-consuming. So we need to estimate the number of different values in each of the dimensions when they are initialized.\r\nAlthough the number of count[ ][ ][ ] and counts[ ][ ] is fixed given the structure, it is impossible to determine how many parent configurations or even which nodes are the parents of a certain node. So in order not to receive exceptions in the project. We initial the count[ ][ ][ ] and count[ ][ ] with maximum value for secure purpose. Also it turns out to save the memories comparing to the condition if we initialize them with a relatively large number.\r\n```\r\ntheta =\r\n new double[2*p_numberOfNode][p_rll[max]*p_rll[max]*p_rll[max]][p_rll[max]];\r\n\r\ncount = new int[2*numberOfNode][rll[max]*rll[max]*rll[max]][rll[max]];\r\n\t\tcounts = new int[2*numberOfNode][rll[max]*rll[max]*rll[max]];\r\n\r\ncount = new int[numberOfNode][rll[max]*rll[max]*rll[max]][rll[max]];\r\n\t\tcounts = new int[numberOfNode][rll[max]*rll[max]*rll[max]];\r\n```\r\n\r\n##Polymorphic\r\n###Polymorphic in scoring function\r\nThe scoring function is where we implement the polymorphism to redefine the method resultOfScore based on different kinds of scoring criterion. Concerning that there are various kinds of algorithm to score and select the best structure independently. We provide the base class scoringfunction where all the attributes are declared in this class.\r\nAlso, we made the scoringfunction class an abstract class with an abstract method resultOfScore, so you can’t not initialize an object of scoringfunction type, instead the specific type is recommended at the beginning.\r\n```\r\npublic abstract class scoringfunction  \r\npublic abstract double resultOfScore();\r\n```\r\n\r\n###Polymorphic in Structure Learning\r\nThe structure learning functions also use polymorphic to make it possible to extend other possible solutions in a gentle way. in our project, structure learning function is like the graph below.\r\nAs can be seen in the graph, the Learn class is abstract and it has 2 abstract function to be override and 1 function that is declared and defined. In the DLearn and SLearn classes, the function learnStructures() and dagGen() are overrided because they behave different when learning BN and DBN.\r\n<a href=\"http://imgur.com/dXcRwvl\"><img src=\"http://i.imgur.com/dXcRwvl.png\" title=\"source: imgur.com\" /></a>\r\n##A little bit more work\r\nAfter finished programming the project, we run our program several times with the sets of data given. The result sometimes appears to be concentrated on only one number, after trying to debug our program, we found that sometimes the possibility of a variable taking different values are same, and after the “find-max” iterate, the first-max value remains. \r\nTo fix that problem, we generate a random list. When the situation above is occurred, a random value with highest score is chosen.  \r\n\r\n##Outcomes & conclusion\r\nThough our program is not tested on the workstation in the Lab. We can ensure that our program can run smoothly on a windows or a Mac with 2 different scoring functions and 2 sets of data. Here is the outcome of our test data on a Macbook.\r\n\r\n\r\n##Group Member\r\n\r\n<center><a href=\"http://imgur.com/PcmSpJn\"><img src=\"http://i.imgur.com/PcmSpJn.png\" title=\"source: imgur.com\" /></a></center>\r\n\r\n\r\n## Agradecimentos\r\n\r\nThank to Prof. Alexandra Carvalho supporting our project, especially for the doubt session in English, we really appreciate that!","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}